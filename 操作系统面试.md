操作系统面试

## Process Management

### Processes

进程的创建过程；进程、线程、协程的区别

#### 进程状态  

新建, 就绪, 运行, 中止, 阻塞. 

僵尸态, 子进程exit 但是没有被父进程wait回收,  解决方法是 kill 或者终止父进程 托管给init进程 , init会定期wait 回收所有僵尸态.

#### 进程控制块

Process Control Block (PCB)    包含了Information associated with each process

 ■ Process state (new, ready, ...)  进程状态

■ Program counter (address of next instruction) PC

■ Contents of CPU registers  CPU寄存器

■ CPU scheduling information (priority)  调度信息比如优先级

■ Memory-management information 内存管理信息

■ Accounting information (cpu/time used, time limits, process number) 
■ I/O status information (allocated devices and opened files)  io 状态信息

上下文切换:   OS把P0进程state 保存到 对应的PCB0 中,   然后reload 另一个进程P1的state from PCB1

#### 进程间通讯

1. 管道
2. names pipes, 磁盘文件形式存在.
3. 信号 send (P, message)  ● receive(Q, message) 
4. 消息队列.**消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点**
5. 信号量 ,一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。
6. 共享内存
7. 套接字 

### Threads

TCB里有 tid, 寄存器组, PC, 调度信息, 线程状态, 栈指针, 线程参数

#### 线程的好处

1. 创建的开销小, 进程的数量是有上限的. 
2. 切换的开销小, 不用context switch, 只需要保存寄存器和stack, 保存变量和函数执行到哪里.  
3. 共享同一个进程的资源, 不用进程间通讯, 

线程共享什么资源?   线程共享 进程的地址空间, 堆内存和全局变量

#### 线程和进程的区别

Ⅰ 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源(堆内存, 全局变量)

Ⅱ 调度

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

Ⅲ 系统开销

由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 寄存器的保存及新调度进程 CPU 寄存器的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

Ⅳ 通信方面

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

#### 锁

内核读写锁

自旋锁. 

### CPU 调度

running -  > wait    and   terminates 是非抢占式

running - > ready  and wait - > ready 是抢占式的.

SJF  最短任务最先调度.  

有两种, 一种是非抢占式,

一种是抢占式, 也叫做 SRTF. Shortest-Remaining-Time-First 每次有一个job进来就会调度它.  这种算法要预测下一次的时间, relies on predicting the next CPU burst based on an average of previous bursts

Shortest Remaining Time First SRTF cannot be implemented because it requires knowledge of the future.

用aging来 防止很长的job starvation.

 结合各种分配方法, 分两个队列, foreground 和back ground 

#### LINUX实现

实时任务 vs 普通任务

 实时任务调度策略： ● SCHED_FIFO，按照任务的先后顺序执行，高优先级的任务可以抢占低优 先级的任务； ● SCHED_RR，为每一个任务分配一定大小的时间片，时间片用完后会将任 务准移到队列的尾部，高优先级的任务可以抢占低优先级的任务； ● SCHED_DEADLINE，优先选择当前时间距离任务截止时间近的任务。 

■ 普通任务调度策略： ● SCHED_NORMAL，普通任务调度策略； ● SCHED_BATCH，后台任务； ● SCHED_IDLE，空闲时才执行。

■ sched_class本身定义了一个抽象接口，具体是现实可以是多样化 的，目前的实现包括：

```c
 // 会停止所有其他线程，不会被其他任务打断，优先级最高的任务会使用 
 extern const struct sched_class stop_sched_class;  
// 对于上面deadline调度策略的执行 
extern const struct sched_class dl_sched_class;  // 对应上面FIFO与RR调度策略的执行，具体哪一个策略，由policy字段指定 
extern const struct sched_class rt_sched_class;  // 对应NORMAL普通调度策略的执行，我们称为公平调度类，其内部采用的 是cfs调度算法，后面会详细说明 
extern const struct sched_class fair_sched_class;  
// 对应IDLE调度策略的执行 
extern const struct sched_class idle_sched_class
```

调度实体用于维护task调度相关的元信息，

其有以下几种： ● 普通任务使用的调度实体 struct sched_entity se;  ● 实时任务使用的调度实体 struct sched_rt_entity rt;  ● deadline调度类的调度实体 struct sched_dl_entity dl;

##### CFS

（Complete Fair Schedule）调度算法的思想是为每一个 task维护一个虚拟的运行时间vruntime， ■ 调度程序优先选择vruntime值最小的任务执行，之所以引入 vruntime的概念，是为了支持优先级调度。 

■ vruntime其实是基于task的实际运行时间及优先级权重计算出来 的值，其计算公式如下： vruntime += delta_exec * NICE_0_LOAD / weight 

● vruntime：虚拟运行时间 ● delta_exec: 实际的执行时间 ● NICE_0_LOAD：进程优先级nice值为0对应的权重值 ■ nice值越小其权重值越大，则最终计算出来的vruntime就会偏小( 列了一个表, 优先级改变就去查表 .) ■ 为了优先获取vruntime最小任务的时间复杂度，LinuxCFS算法 的实现上采用红黑树的数据结构，其具体实现是运行队列中的 cfs_rq。

##### 运行队列

对于每一个CPU都会有一个rq的结构体，维护着所有待运行的任 务，我们称之为运行队列（running queue）

rq 队列包括 cfs , 实时和deadline 三种队列.

### 进程同步

线程同步和互斥的机制

1. **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
2. **信号量(Semphares)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
3. **事件(Event)** :Wait/Notify

### 死锁

resource allocation 没有环, 肯定不会死锁.    有环, if only one instance per resource type 就会死锁,  if several instances per resource type, 有可能死锁.

死锁的四个必要条件: 资源不能共享 Mutual exclusion,  已经获得的不释放hold and wait, 不能抢占 No preemption, 循环等待 Circular wait

#### 死锁预防

在设计程序的时候考虑死锁预防

考虑 Hold and Wait – 确保当进程请求资源的时候, 不会占有别的资源. 

考虑 No preemption -  如果请求一个资源失败, 进程就立刻释放占有的所有资源

考虑 Circular wait - 给所有资源编个号排个序. 

#### 死锁避免

程序运行时用死锁避免算法动态考虑是否分配. 

每个进程声明它可能需要的每种类型资源的最大数量。
死锁避免算法动态检查资源分配状态，以确保永远不会出现循环等待情况。
资源分配状态由可用和已分配资源的数量以及进程的最大需求定义.当进程请求可用资源时，系统必须决定立即分配是否使系统处于安全状态。

怎么判断?  safe state . 考试会考是否在安全状态, 什么是安全状态

unsafe state 也不一定死锁. 只是可能死锁

##### 避免算法

Single instance of a resource type. Use a resource-allocation graph. 因为有环就死锁. 时间复杂度是 n平方, 因为图中找环很慢,是 n平方的时间复杂度. 

Multiple instances of a resource type.  用银行家算法

死锁检测, 用资源分配图

#### 死锁恢复

##### 结束进程

按进程优先级顺序逐个abort 进程, 直到死锁解除. 

##### Resource Preemption

选一个进程结束, 返回safe state, 但是可能导致 starvation.

##### 进程回退

设置还原点回退到回避死锁的地步. 

## Memory Management

### 分页

 逻辑地址空间可以是不连续的.process is allocated 物理内存whenever the latter is available
 物理内存分成固定大小的块  called frames (size is power of 2, between 512 bytes and 8,192 bytes) 实际物理内存对应的页就是页框
 Divide logical memory into blocks of same size called pages 

 Keep track of all free frames 

 To run a program of size n pages, need to find n free frames and load program

#### 分配内存方法

 First-fit: 分配给first hole that is big enough. 最简单, 通常最快最好.  但是容易出现大量小的空闲分区.  增加了查找开销. 
 Best-fit: Allocate the smallest hole that is big enough; must search entire list, unless ordered by size : 好处 Produces the smallest leftover hole  缺点: 产生最多的外部碎片. 
 Worst-fit: Allocate the largest hole; must also search entire list 特点:  Produces the largest leftover hole  性能非常差, 很快就没有可用的内存块了.

First-fit and best-fit better than worst-fit in terms of speed and storage utilization

合并的时候, 算法会空闲分区链 空间从小到大排序.

### external fragmentation

外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。外部碎片是除了任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请.


物理地址由MMU计算得到,  逻辑地址由CPU计算得到. 

怎么指向页表?  

Page-table base register (PTBR) points to the page table  

Page-table length register (PTLR) 存储了页表大小

#### TLB

每次要先访问页表, 然后访问物理内存,  访问两次太慢, 所以在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache.   a special fast-lookup hardware cache called associative memory or translation look-aside buffers (TLB快表)

可能一次访问, 可能两次访问, 取决于有没有在快表找到. 一般命中率90%以上.  

进程一开始, page table是空的. 所有bit都是invalid

内存不够了就会page fault , bit 把v改成i, 空间分配给别的进程.

每个进程物理地址不容易分配. 所以给每个进程连续的逻辑空间.

#### 三种页表

Hierarchical Paging 多级页表

多级页表, 好处,  如果只有3个地址所在的page 被用到, 只需要 2^4 + 2 *2^4 . 可以节省空间 

保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）

 Hashed Page Tables 

先hash , 然后找链表, 链表法.  Hash paging 可以和inverted paging一起用 .Hash-based paging sometimes requires more memory accesses因为 hash collision

 Inverted Page Tables

page 太多, 放不进去,而且内存很小的时候, 可以直接给物理内存维护页表. 

好处: 整个os只用维护一个page table 

### 分段

对用户友好, 允许维护逻辑上的虚拟空间, 方便人维护 

• sharing, protection
Page is good physical unit of information 

• simple memory management
Best of both • segmentation on top of paging

分段系统的逻辑地址结构由段号(段名)和段内地址(段内偏移量)所组成。

段号的位数决定了每个进程最多可以分几个段， 段内地址位数决定了每个段的最大长度是多少 

- 多个互相独立的称为**段(segment) 的地址空间**。每个段由一个从0到最大的线性地址序列构成。各个段的长度可以是0到某个允许的最大值之间的任何一个值。不同的段的长度可以不同，并且通常情况下也都不相同。段的长度在运行期间可以动态改变，比如，堆栈段的长度在数据被压入时会增长，在数据被弹出时又会减小。
- 因为每个段都构成了一个独立的地址空间，所以它们可以独立地增长或减小而不会影响到其他的段。
- 要在这种分段或二维的存储器中指示一个地址，程序必须提供两部分地址：**一个段号和一个段内地址**。
- 分段也有助于在几个进程之间共享过程和数据 一个常见的例子就是共享库(shared library)。

- 分段和分页的实现本质上是不同的:页面是定长的而段不是。
- 在系统运行一段时间后内存被划分为许多块，一些块包含着段，一些则成了空闲区，这种现象称为外部碎片(external fragmentation)。  可以用内存交换解决,  在 Linux 系统里，也就是我们常看到的 Swap 空间，用于内存与硬盘的空间交换。 但是如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。 因为硬盘IO 很慢

先找段表, 再找页表

### 虚拟内存

虚拟内存给每个进程提供了一个一致的, 私有的地址空间. 有效管理内存防止出错. 

可以拥有超过物理内存大小的可用内存. 把内存拓展到硬盘空间. 

保护了每个进程的地址空间不会被其他进程破坏. 

编译后每个文件.o都是逻辑地址从0开始. 链接ld的时候就会重定位, 形成整个程序的完整逻辑地址空间. 

#### linux  内存管理

malloc分配对象，slab

Linux操作系统采用了请求式分页虚拟存储 管理方法。
系统为每个进程提供了4GB的虚拟内存空间。 各个进程的虚拟内存彼此独立。Kernel space uses 1G virtual memory, while each of the user processes has its own 3G virtual memory. 共享1GB的内核空间 

每个程序经编译、链接后形成的二进制映像文件有一个代码段和数据段
■ 进程运行时须有独占的堆栈空间

一个进程的用户地址空间主要由mm_struct结构和 vm_area_structs结构来描述。 可能会考
■ mm_struct结构它对进程整个用户空间进行描述（称为内存表述符memory descriptor）
■ vm_area_structs结构对用户空间中各个区间(简称虚存区)进行描述

vm_area_struct结构是虚存空间中一个连续的区域，在这个区域中的信息具有相同的操作和访问特性。
■ 各区间互不重叠,按线性地址的次序链接在一起。 当区间的数目较多时,将建立AVL树以保证搜索速度。AVL 有插入 ,删除就要旋转,  查询比较快, 维护代价高. 红黑树 维护代价小

##### Linux的分页存储管理机制

Linux的页表机制：
■ Linux假定处理器支持三级页表结构。在64位体系结构上采用三级页表机制。对于以IA32体系结构的32位机器,则采用二级页表机制，页中间目录层实际不起作用。
■ 三级分页管理把虚拟地址分成四个位段： 页目录、页中间目录、页表、页内偏移。
■ 系统设置三级页表： ✦ 页目录PGD（Page Directory） ✦ 页中间目录PMD（Page Middle Directory） ✦ 页表PTE（Page Table）
■ 2.6.11以后Linux内核采用四级页表模型来使用硬件分页机制 (支持64位CPU架构) 

##### 内存页大小

是否可以修改?

HugePages是Linux内核的一个特性，它允许更大的页面管理内存，以替代4KB的页面大小。Huge pages 有两种格式大小： 2MB 和 1GB ， 2MB 页块大小适合用于 GB 大小的内存， 1GB 页块大小适合用于 TB 级别的内存； 2MB 是默认的页大小。

大页和小页的优点缺点?

优点:  取代传统的4kb内存页面，使得管理虚拟地址数变少，加快了从虚拟地址到物理地址的映射. 页表占用内存变小, 降低TLB的 cache miss. 减少花费在内存管理上的CPU时间.   基于共享内存的多进程架构的程序容易存在页表超过1GB的问题。适合大内存或内存密集型应用（例如数据库）的调优。

缺点: 第一， 首先开启该功能需要进行额外设置，不同的数据库配置方法不同。 第二， 大页内存一旦设置，内存就实际分配出去了，也会一直驻留在内存中，不会被交换出去。 分配了后有很多intern 碎片.   

大页如何管理?

huge page的分配走的是伙伴系统

大page和小page的优缺点是什么? 

小page的缺点:  page table 占用空间大, 

大page的缺点:   大页内存一旦设置，内存就实际分配出去了，也会一直驻留在内存中，不会被交换出去。分配了后有很多intern 碎片.   

#### 页替换策略

FIFO  在内存中停留时间最长的. 会考 Belady’s Anomaly: more frames ⇒ more page faults.  LRU 性能较好, 但是需要寄存器和栈的硬件支持, 不会出现belady 异常. FIFO会有belady异常

Second chance 也叫做NRU not recently use

#### page fault

page fault 又分为几种:  major page fault、 minor page fault、 invalid(segment fault)。

major page fault 也称为 hard page fault, 指需要访问的内存不在虚拟地址空间，也不在物理内存中，需要从慢速设备载入。swap 回到物理内存也是 hard page fault。

minor page fault 也称为 soft page fault, 指需要访问的内存不在虚拟地址空间，但是在物理内存中，只需要MMU建立物理内存和虚拟地址空间的映射关系即可。

1. 当一个进程在调用 malloc 获取虚拟空间地址后，首次访问该地址会发生一次soft page fault。
2. 通常是多个进程访问同一个共享内存中的数据，可能某些进程还没有建立起映射关系，所以访问时会出现soft page fault

invalid fault 也称为 segment fault，指进程需要访问的内存地址不在它的虚拟地址空间范围内，属于越界访问，内核会报 segment fault错误。

页面异常的处理程序是do_page_fault( )函数， 该函数有两个参数：
Ø一个是指针,指向异常发生时寄存器值存放的地址。
Ø另一个错误码,由三位二进制信息组成： 

ü第0位——访问的物理页帧是否存在； ü 第1位——写错误还是读错误或执行错误； ü 第2位——程序运行在核心态还是用户态。

do_page_fault()函数的执行过程如下：

 Ø 首先得到导致异常发生的线性地址（虚拟地址）,对于 IA32该地址放在CR2寄存器中。
Ø 检查异常是否发生在中断或内核线程中,如是,则进行出 错处理。
Ø 检查该线性地址属于进程的某个vm_area_struct区间。 如果不属于任何一个区间,则需要进一步检查该地址是 否属于栈的合理可扩展区间。一但是用户态产生异常 的线性地址正好位于栈区间的vm_start前面的合理位 置,则调用expand_stack( )函数扩展该区间,通常是扩 充一个页面,但此时还未分配物理页帧。 至此,线性地址必属于某个区间。

Ø根据错误码的值确定下一个步骤: ● 如果错误码的值表示为写错误,则检查该区间是否允 许写,不允许则进行出错处理。
● 如果允许写就是属于写时拷贝(COW)。如果错误码 的值表示为页面不存在,这就是所谓的按需调页 (demand paging)。

写时拷贝的处理过程：
n 首先改写对应页表项的访问标志位，表明其刚被访问过, 这样在页面调度时该页面就不会被优先考虑。
n 如果该页帧目前只为一个进程单独使用,则只需把页表项置为可写。
n 如果该页帧为多个进程共享,则申请一个新的物理页帧并 标记为可写,复制原来物理页帧的内容,更改当前进程相应 的页表项,同时原来的物理页帧的共享计数减一。

按需调页的处理过程:
n 第一种情况页面从未被进程访问,这种情况页表项的值全为0。 

(1)如果所属区间的vm_ops->nopage不为空,表示该区间映射到一个文件,并且vm_ops->nopage指向装入页面的函数,此时调用该 函数装入该页面。
(2)如果vm_ops或vm_ops->nopage为空,则该调用do_anonymous_page( )申请一个页面；
n 另一种情况是该页面被进程访问过,但是目前已被写到交换分区, 页表项的存在标志位为0,但其他位被用来记录该 页面在交换分区中的信息。调用do_swap_page( )函数从 交换分区调入该页面。

Linux使用最近最少使用（LRU）页面置换算法来公平地选择将要从系统中换出的页面。
■ 这种策略为系统中的每个页面设置一个age，它随页面访问次数而变化。页面被访问的次数越多则页面年龄越年轻；相反则越衰老。older页面是待交换页面的最佳侯选者。

在Linux中，进行交换的单位是page而不是进程 

■ 在页面交换中，页面置换算法是影响交换性能的关键性指标，其复杂性主要与换出有关：
● 哪种页面要换出 ● 如何在交换区中存放页面 ● 如何选择被交换出的页面

代码段, 内核中的PCB 和stack 不会被置换出去.  

#### buddy伙伴算法

■ Linux把空闲的页帧按照页块大小分组进行管理，数组 free_area[]来管理各个空闲页块组。

伙伴系统是以页帧为基本分配单位, 因而对于小对象容易造成内部碎片。
■ 不同的数据类型用不同的方法分配内存可能提高效率。比如需要初始化的数据结构，释放后可以暂存着，再分配时 就不必初始化了。内核的函数常常重复地使用同一类型的内存区，缓存最近释放的对象可以加速分配和释放。
■ 解决办法：基于伙伴系统的slab分配器。 ■ slab分配器的基本思想：为经常使用的小对象建立缓冲, 小对象的申请与释放都通过slab 分配器来管理。slab 分配 器再与伙伴系统打交道。
■ 好处：其一是充分利用了空间,减小了内部碎片；其二是 管理局部化,尽可能少地与伙伴系统打交道,从而提高了效率。

#### thrash

更换页面时，如果更换页面是一个很快会被再次访问的页面，则再次缺页中断后又很快会发生新的缺页中断。整个系统的效率急剧下降------这种现象称为颠簸thrash（抖动）

内存颠簸的解决策略是：

1-如果是因为页面替换策略失误，可修改替换算法来解决这个问题 to intersect the running of I/O bound and CPU bound processes

2-如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要减少程序的数量。

3-否则，还剩下两个办法：1终止该进程；2增加物理内存容量；

#### 地址翻译的过程

虚拟地址包括  虚拟页号和页内偏移.  虚拟页号可以分成 TLB tag 和组index.  物理地址分为物理页号和页内偏移.  可以把物理页号等于cache tag, 页内偏移分成 cache 索引和偏移量. 

 先把十六位虚拟地址转  二进制, 找到组index=3 和 TLB tag=3 .查询TLB tag有3, 有效位为1 . 就可以查出来. 

物理内存不够, 就需要paging disk.  如果内存不足，OS和 SQL Server 会在物理内存和文件缓存之间做大量的Paging 动作（Page的换进和换出

swap 建议内存的2倍大小, 不可以小于一倍大小. 

Process Creation
 Virtual memory 还有其他好处 during process creation: - Copy-on-Write - Memory-Mapped Files (later)

之前讲了用户的内存是怎么分配的. 但是操作系统也需要内存. 

那么, 操作系统是怎么allocate内存的?  请学习buddy system. 

虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换

通过内存地址虚拟化，可以在没有访问某虚拟内存地址时不分配具体的物理内存，在实际访问某虚拟内存地址时操作系统再动态地分配物理内存，建立虚拟内存到物理内存的页映射关系，这种技术称为按需分页（demand paging）

把不经常访问的数据所占的内存空间临时写到硬盘上，这样可以腾出更多的空闲内存空间给经常访问的数据；当CPU访问到不经常访问的数据时，再把这些数据从硬盘读入到内存中，这种技术称为页换入换出（page swap in/out）。这种内存管理技术给了程序员更大的内存“空间”，从而可以让更多的程序在内存中并发运行。

#### MMU

Memory Management Unit是一种负责处理CPU的内存访问请求的计算机硬件。它的功能包括虚拟地址到物理地址的转换（即虚拟内存管理）、内存保护、中央处理器高速缓存的控制。MMU位于处理器内核和连接高速缓存以及物理存储器的总线之间。如果处理器没有MMU，CPU内部执行单元产生的内存地址信号将直接通过地址总线发送到芯片引脚，被内存芯片接收，这就是物理地址。如果MMU存在且启用，CPU执行单元产生的地址信号在发送到内存芯片之前将被MMU截获，这个地址信号称为虚拟地址，MMU会负责把VA翻译成相应的物理地址，然后发到内存芯片地址引脚上。

简而言之，当处理器内核取指令或者存取数据的时候，会提供一个虚拟地址，这个地址是可执行代码在编译的时候由链接器生成的。MMU负责将虚拟地址转换为物理地址，以在物理存储器中访问相应的内容。

## storage management

### file system interface

#### NDFS

问namenode ， 会告诉你去哪里data node

### 文件系统implement

Virtual File Systems (VFS) 提供一种面向对象的方式来implementing file systems , java和C调用的都是VFS的文件接口。

怎么找到 FCB？ hash 或者顺序查找。 

找到FCB后， 怎么存数据？ 

三种方法， 1  contiguous 2 linked  3 indexed 

连续contiguous ， 有时候找不到足够大的空间。 优点是实现简单, 存取速度快.  缺点是文件长度难动态增加. 

#### linked 

Simple – need only starting address  Free-space management system – no waste of space  缺点:  No random access, poor reliability

链表的方式存放是**离散的，不用连续的**，可以**消除磁盘碎片**，可大大提高磁盘空间的利用率，同时**文件的长度可以动态扩展**。

#### indexed allocation

outer index ->  index table .  mapping

索引的方式优点在于：

- 文件的创建、增大、缩小很方便；Adjustable to any size of files 
- 不会有碎片的问题；
- 支持顺序读写和随机读写；从10th logical block 访问3rd logic block 只用1次disk blocks access.

缺点: 大文件随机访问慢

 Need index table (analogous to page table)

Combined Scheme: UNIX ext2/3 (4K bytes per block)

Inode 

■ File information ■ The first 12 pointers point directly to data  blocks ■ The 13th pointer points to an index block ■ The 14th pointer points to a block containing  the addresses of index blocks ■ The 15th pointer points to a triple index  block

先渲染前两页, 后面慢慢读.   前面的是 direct blocks, 后面的 io数也比较多.  可能是两层 indirect , 三层 indirect.

#### free space management

空闲表法

bit vector   位图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。  这算开创新性的论文

linked free space on disk. 当创建文件需要一块或几块时，就从链头上依次取下一块或几块。反之，当回收空间时，把这些空闲块依次接到链头上。

这种技术只要在主存中保存一个指针，令它指向第一个空闲块。其特点是简单，但不能随机访问，工作效率低，因为每当在链上增加或移动空闲块时需要做很多 I/O 操作，同时数据块的指针消耗了一定的存储空间。空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太大。一开始有序， 但是后来就乱序了。 分配速度快。 这算 改进的论文。

grouping的方法，  把连续的几个块group到一起。 这算 普通的论文， 是缝缝补补的论文。 可中可不中。 

linked  

文件系统的要点： 第一个disk allocation

第二个，怎么快速找文件。 

NFS主要工作是什么？ 

三种磁盘的分配方法。  要熟悉

 熟悉 index ， 熟悉 unix的数据结构。  要理解和认识， 会计算 unix 的最大空间

#### linux文件系统

字符设备文件和块设备文件。Linux把对设备的I/O作为对 文件的读取/写入操作内核提供了对设备处理和对文件处理的统一接口。 

● fd0 (for floppy drive 0) ● hda (for harddisk a) 

● lp0 ( for line printer 0) ● tty(for teletype terminal

管道(PIPE)文件：用于在进程间传递数据。Linux对管道的操作与文件操作相同，它把管道当作文件进行处理。

socket文件

文件系统分三大类： ● 基于磁盘的文件系统，如ext2/ext3/ext4、VFAT、NTFS等。 ● 网络文件系统，如NFS等。 ● 特殊文件系统，如proc文件系统、devfs、sysfs（/sys）等。 

/proc 虚拟文件系统，在这里可以获取系统状态信息并且修改系统的某些配置信息。 ■ 如内存情况在/proc/meminfo文件中，使用命令

■ 支持多种不同类型的文件系统是Linux操作系统的一大特 色。如：ext、ext2、ext3、ext4、minix、iso9660 、 hpfs 、 msdos 、 vfat 、proc 、 nfs 、smb 、 sysv 、ntfs 、ufs、jfs、yaffs 、ReiserFS、 CRAMFS、JFFS2等

Linux在标准内核中已支持的文件系统超过50种。 如果你实现了一个myfilesystem, 也可以认证.

做一个虚拟层,  各种不同物理文件系统转换为一个具有统一 共性的虚拟文件系统。这种转换机制称为虚拟文件系统转 换VFS(Virtual Filesystem Switch/System) 。VFS并不是一种实际的文件系统。ext2/ext4等物理文件系 统是存在于外存空间的，而VFS仅存在于内存。 ■ 在 VFS 上面，是对诸如 open、close、read 和 write 之 类的函数的一个通用 API 抽象。在 VFS 下面是文件系统 抽象，它定义了上层函数的实现方式。文件系统的源代码 可以在 linux/fs 中找到。

很重要的是学习怎么做这种中间件, 因为很多地方都需要这种.

■ Linux的标准文件系统是ext2或ext3或ext4，系统把它的 磁盘分区做为系统的根文件系统。

#### VFS

虚拟内存系统 VFS根据不同的文件系统抽象出了一个通用的文件模型。通用的文件模型由四种数据对象组成： 

● 超级块对象 superblock :存储文件系统的信息 contains all file system configuration parameters

● 索引节点对象 inode object ：存储某个文件的信息。 通常对应磁盘文件系统的文件控制块   fat32 inode实现 一个链表,  ext32是索引结构. 

● 目录项对象dentry object ：dentry对象主要是描述一 个目录项，是路径的组成部分。 ● 文件对象 file object：存储一个打开文件和一个进程的 关联信息。只要文件一直打开，这个对象就一直在内存。

```c
struct super_block {
struct list_head s_inodes;// inodes 很多, 都在磁盘里. 
struct list_head s_dirty;
}
```

在系统运行中， VFS要建立、撤消一些VFS inode，还要对VFS超级块进行一些必要的操作。这些操作由一系列操作函数实现。 ■ 不同类型的文件系统的组织和结构不同，完成同样功能的操作函数的 代码不同，每种文件系统都有自己的操作函数。  如何在对某文件系统进行操作时就能调用该文件系统的操作函数呢？ 这是由VFS接口通过转换实现的。 ■ 在VFS超级块中s_op是一个指向super_operations结构的指针， super_operations中包含着一系列的操作函数指针，即这些操作函 数的入口地址。 

■ 每种文件系统VFS超级块指向的super_operations中记载的是该文件 系统的操作函数的入口地址。只需使用它们各自的超级块成员项s_op， 以统一的函数调用形式：s_op->read_inode()就可以分别调用它们各自的读inode操作函数

产生 super block , 修改superblock , 对superblock 支持的inode进行操作.

```c
struct inode { 
nlink_t i_nlink; /* 该文件的链接数 */
uid_t i_uid; /* 文件所有者的用户标识 */
gid_t i_gid; /* 文件的用户组标识 */
time_t i_atime; /* 文件最后一次访问时间 */
time_t i_mtime; /* 文件最后一次修改时间 */
time_t i_ctime; /* 文件创建时间 */
unsigned long i_blksize; /* 块尺寸，以字节为单位 */
unsigned long i_blocks; /* 文件的块数 */
struct inode_operations *i_op; /* 指向inode操作函数入口表的指针 */
    
}
```

目录项对象dentry object ■ 每个文件除了有一个索引节点inode数据结构外，还有一个 目录项dentry数据结构。 ■ 每个dentry代表路径中的一个特定部分。如：/、bin、vi都 属于目录项对象。 ■ 目录项也可包括安装点，如：/mnt/cdrom/foo，/、mnt、 cdrom、foo都属于目录项对象。 ■ 目录项对象作用是帮助实现文件的快速定位，还起到缓冲作用

块设备是i/o设备中的一类，是将信息存储在固定大小的块中，每个块都有自己的地址，还可以在设备的任意位置读取一定长度的数据，例如硬盘,U盘，SD卡等。

1.SCSI硬盘 —— 以sd开头。 例如：sda表示第一块SCSI硬盘、sdb表示第二块SCSI硬盘、sda1表示第一块SCSI硬盘的第一个分区。 2.IDE硬盘 —— 以hd开头。

EXT3是**第三代扩展文件系统**（ 英语 ：Third extended filesystem，缩写为ext3），是一个日志文件系统，常用于 Linux操作系统 。             

#### 进程的文件管理

 ● 对于一个进程打开的所有文件，由进程的两个私有结构进行管理。 fs_struct结构记录着文件系统根目录root和pwd当前目录，  files_struct结构包含着进程的打开文件表

 fd[]每个元素是一个指向file结构体的指针，该数组称为进程打开文件表。 

■ 进程打开一个文件时，建立一个file结构体，并加入到系 统打开文件表中，然后把该file结构体的首地址写入fd[]数 组的第一个空闲元素中，一个进程所有打开的文件都记载 在fd[]数组中。

■ fd[]数组的下标称为**文件描述符** file description。 ■ 在Linux中，进程使用文件名打开一个文件。 在此之后对 文件的识别就不再使用文件名，而直接使用文件描述符。 ■ 在系统启动时文件描述符0、1、2由系统分配: 0标准输入 设备，1标准输出设备，2标准错误输出设备。 ■ 当一个进程通过fork()创建一个子进程后，子进程共享父进程的打开文件表，父子进程的打开文件表中下标相同的 两个元素指向同一个file结构。 这时file的f_count计数值增1。 ■ 一个文件可以被某个进程多次打开，每次都分配一个file 结构，并占用该进程打开文件表fd[]的一项，得到一个文 件描述符。但它们的file结构中的f_inode都指向同一个 inode

ext2的绝大多数的数据结构和系统调用与经典的UNIX一致。 ■ 能够管理海量存储介质。支持多达4TB的数据，即一个分区的容量 最大可达4TB。 ■ 支持长文件名，最多可达255个字符，并且可扩展到1012个字符 ■ 允许通过文件属性改变内核的行为；目录下的文件继承目录的属性。 ■ 支持文件系统数据“即时同步”特性，即内存中的数据一旦改变， 立即更新硬盘上的数据使之一致。 ■ 实现了“符号连接”（symbolic links）的方式，使得连接文件只需要存放inode的空间。 ■ 允许用户定制文件系统的数据单元（block）的大小，可以是 1024、 2048 或 4096 个字节，使之适应不同环境的要求。 ■ 使用专用文件记录文件系统的状态和错误信息，供下一次系统启动时决定是否需要检查文件系统 

### I/O  system

#### RAID

redundant array of independent disks  考过这个. 

RAID0 只做切片不做副本.  要每个磁盘容量一样不然浪费空间.

RAID 1:  reliability 最高. 一比一备份

RAID5和RAID4一样，数据以块为单位分布到各个硬盘上。RAID 5不对数据进行备份，而是把数据和与其相对应的[奇偶校验](https://baike.baidu.com/item/奇偶校验)信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上。当RAID5的一个磁盘数据损坏后，利用剩下的数据和相应的奇偶校验信息去恢复被损坏的数据。

RAID 6: extra redundancy information to guard multiple disk failures. Capacity = min(disk sizes) * (n-2) 允许最多两个磁盘错误. 比5的开销更大. 

现实中,  

大部分用 RAID1 .最安全, 

RAID2用汉明码太复杂,  现实中不用.

RAID3 用了 parati , bottleneck , 不用

RAID5 也常用. 

RAID6太复杂, 存多个奇偶校验码, 计算慢, 也不常用. 

#### HDFS

HDFS is not designed for  : 

1. Low-latency reads, HDFS适合大吞吐量,    HBase addresses this issue 

2. large amount of small files   一般用于大于100MB的文件, 
3. Single writer per file.    一般用于多个 writer, Writes only at the end of file, no-support for arbitrary offset

Architecture of HDFS
❻ One Namenode ❻ One Second Namenode ❻ Multiple Datanode

Hadoop现在更新到3.0 了

java 写的, 提供原生的java api

YARN来管理结点.  用raft 分布式协议

有一个PCI bus 把 graphics 控制器,  memory 控制器,  IDE disk控制器和 expansion bus interface 连起来

Device I/O Port Addresses on PCs . 

用户态到内核态的三种情况

1. 用户进程执行 trap 指令,比如一个system call, trap 也叫 同步软中断.
2. 用户进程 造成一个异常, 比如除以0, access bad address. page fault等
3. 接收到interrupt 后处理器转到内核态 

用户程序系统调用-> 内核调用处理程序-> 设备驱动程序 ->硬件中断

首次打开文件, 是FCB文件控制块读入内存.

controller 有什么东西?  

1. I/O Port Registers. 四大寄存器, data-in 设备的数据放在这里给host也就是CPU,   data-out, status 设备运行状态是繁忙还是等待, control

#### interrupt  

三类,  一个是 hardware  的IRQ 中断请求. 一个是 processor 的exception/trap , 一个是 软中断. 

DMA为什么可以截获 中断? 因为是通过PCI总线发送的. 

所有数据到buffer , 然后DMA告诉CPU去处理. 

DMA有 burst mode,  cycle stealing mode 和 transparent mode. 

 cycle stealing mode  每次CPUcycle 做完了跑一次DMA, 数据的读取打散了.

 transparent mode 由DMA controller 来决定每次多长时间读取. 



#### 系统调用

`strace ls` 追踪ls 的内核调用

用户调用fork -> eax=2（保存系统调用号到寄存器中） 

■ int 0x80 （触发中断，切换到内核态） 

■ 在中断向量表中查找（0x80号），执行0x80对应的中断服务程序（ system_call） 

■ 在系统调用表中找到系统调用号为2的那一项（通过之前保存的 eax=2） -> 执行系统调用（sys_fork

一个进程栈的默认大小是1M

系统调用时把 用户态保护的信息压入内核栈,  内核执行结束, 内核栈中保护数据弹出, 恢复用户态栈.

system_call()函数实现了系统调用中断处理程序 ：

1. 它首先把系统调用号和该异常处理程序用到的所有CPU寄 存器保存到相应的栈中， SAVE_ALL 
2. 把当前进程task_struct （thread_info）结构的地址存放 在ebx中 
3. 对用户态进程传递来的系统调用号进行有效性检查。若调 用号大于或等于NR_syscalls，系统调用处理程序终止。 （sys_call_table） 
4. 若系统调用号无效，函数就把-ENOSYS值存放在栈中eax 寄存器所在的单元，再跳到ret_from_sys_call() 
5. 根据eax中所包含的系统调用号调用对应的特定服务例程

##### 系统调用中参数传递

每个系统调用至少有一个参数，即通过eax寄存器传递来 的系统调用号 

■ 用寄存器传递参数必须满足两个条件： ● 每个参数的长度不能超过寄存器的长度 ● 参数的个数不能超过6个（包括eax中传递的系统调用号），否则， 用一个单独的寄存器指向进程地址空间中这些参数值所在的一个 内存区即可 

■ 在少数情况下，系统调用不使用任何参数 

■ 服务例程的返回值必须写到eax寄存器中

### **零拷贝 (Zero-copy)**

零拷贝技术是指计算机执行操作时，**[CPU](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8)**不需要先将数据从某处**[内存](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E5%AD%98%E5%8F%96%E5%AD%98%E5%82%A8%E5%99%A8)**复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省 CPU 周期和**[内存带宽](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E5%86%85%E5%AD%98%E5%B8%A6%E5%AE%BD)**。

#### **Zero-copy 能做什么？**

- 减少甚至完全避免操作系统内核和用户应用程序地址空间这两者之间进行数据拷贝操作，从而减少用户态 -- 内核态上下文切换带来的系统开销。
- 减少甚至完全避免操作系统内核缓冲区之间进行数据拷贝操作。
- 帮助用户进程绕开操作系统内核空间直接访问硬件存储接口操作数据。
- 利用 DMA 而非 CPU 来完成硬件接口和内核缓冲区之间的数据拷贝，从而解放 CPU，使之能去执行其他的任务，提升系统性能。

#### **Zero-copy 的实现方式有哪些？**

- **减少甚至避免用户空间和内核空间之间的数据拷贝**：在一些场景下，用户进程在数据传输过程中并不需要对数据进行访问和处理，那么数据在 Linux 的 `Page Cache` 和用户进程的缓冲区之间的传输就完全可以避免，让数据拷贝完全在内核里进行，甚至可以通过更巧妙的方式避免在内核里的数据拷贝。这一类实现一般是通过增加新的系统调用来完成的，比如 Linux 中的 mmap()，sendfile() 以及 splice() 等。

   mmap 就是把用户进程空间的一段内存缓冲区（user buffer）映射到文件所在的内核缓冲区（kernel buffer）上。通过这种方式，有两个优点：一是节省内存空间，因为用户进程上的这一段内存是虚拟的，并不真正占据物理内存，只是映射到文件所在的内核缓冲区上，因此可以节省一半的内存占用；二是省去了一次 CPU 拷贝，对比传统的 Linux I/O 读写，数据不需要再经过用户进程进行转发了，而是直接在内核里就完成了拷贝

- **绕过内核的直接 I/O**：允许在用户态进程绕过内核直接和硬件进行数据传输，内核在传输过程中只负责一些管理和辅助的工作。

  
