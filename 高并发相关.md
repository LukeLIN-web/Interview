# 高并发相关

面试官之问：知道你的接口“QPS”是多少吗？

**QPS（Query Per Second）：每秒请求数，就是说服务器在一秒的时间内处理了多少个请求。**

那我们怎么估出每秒钟能处理多少请求呢？

用日志来估计！细分下来，有两种方式。

*方式一:自己在接口里记录*

这种方式指的是在你的接口里，日志记录了能体现该接口特性的，并具有唯一性的字符串！

```text
 logger.info("渣渣烟");
```

只在index这个接口里出现过，没在其他其他接口里出现过！因此，只要统计出"渣渣烟"这个字符串在日志里的出现次数，就能知道该接口的请求次数！

*方式二:利用tomcat的access log*

我们现在估计出了单机的QPS。接下来，估算集群的QPS。

这就要根据负载均衡的策略来估计！

比如，你部署了32台机器，负载均衡的策略恰巧为轮询，那集群的QPS就是单机的QPS乘32就好了。

聊天室支持多少并发？ 受哪些因素影响？

网络-硬盘读写速度-内存大小-cpu处理速度。 CPU需要处理的上下文切换也越多，额外增加了CPU的消耗，导致平均响应时间增加。

更多并发应该怎么做？

1. 减少数据访问-> 减少磁盘访问 .使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间；
2. 返回更少数据， 返回数据压缩 -> 减少网络传输
3. 减少交互次数 -> 减少网络传输

4. 减少cpu和内存开销
5. 增加资源, 多一个机器.cpu负载降低, 增强单机硬件性能，例如：增加CPU核数如32核，升级更好网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；CPU 越多性能越高，分配给 JVM 的内存越多性能也就越高，但也会加重 GC 的负担。

**什么是反向代理？**
回答：[proxy]代表[被访问的服务器]，此时proxy是**反向代理**。

例如：web-server希望对用户屏蔽高可用、屏蔽web-server扩展、web-server内网ip等细节，于是就找了一个proxy隔在中间，此时proxy代表web-server集群，**用户以为proxy的ip就是被访问web-server的ip**（web-server是集群，具体访问了哪个web-server，用户不知道），由于web-server集群有多台，此时反向代理服务器要具备**负载均衡**的功能。**什么是反向代理？**
回答：[proxy]代表[被访问的服务器]，此时proxy是**反向代理**。

### 负载均衡

负载均衡设备在接收到第一个来自客户端的 SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标 IP 地址进行修改（改为后端服务器 IP），直接转发给该服务器。TCP 的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。

1. 在四层负载均衡的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个 Web 服务器的负载均衡，除了根据 VIP 加 80 端口辨别是否需要处理的流量，还可根
2. 据七层的 URL、浏览器类别、语言来决定是否要进行负载均衡。举个例子，如果你的 Web 服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。
3. 以常见的 TCP 为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接（三次握手）后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立 TCP 连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。



### 高并发怎么办?哪里会先出问题? 

- **系统集群化**
- **数据库层面的分库分表+读写分离**
- **针对读多写少的请求，引入缓存集群**
- **针对高写入的压力，引入消息中间件集群**，

如果你的系统内处理的是较为复杂的一些业务逻辑，是那种重业务逻辑的系统的话，是比较耗费CPU的。

你可以在前面挂一个负载均衡层，把请求均匀打到系统层面，让系统可以用多台机器集群化支撑更高的并发压力。比如说这里假设给系统增加部署一台机器，那么每台机器就只有250/s的请求了。

然后 , 数据库不行了 

得对系统做分库分表 + 读写分离，也就是把一个库拆分为多个库，部署在多个数据库服务上，这是作为主库承载写入请求的。

然后每个主库都挂载至少一个从库，由从库来承载读请求。

然后, 不能只加机器,

你完全可以根据系统的业务特性，对那种**写少读多的请求，引入缓存集群**。

具体来说，就是在写数据库的时候同时写一份数据到缓存集群里，然后用缓存集群来承载大部分的读请求。

这样的话，通过缓存集群，就可以用更少的机器资源承载更高的并发。

- **不要盲目进行数据库扩容，数据库服务器成本昂贵，且本身就不是用来承载高并发的**
- **针对写少读多的请求，引入缓存集群，用缓存集群抗住大量的读请求**

#### 引入消息中间件集群

假如说，你现在每秒是1000/s次写请求，其中比如500次请求是必须请求过来立马写入数据库中的，但是另外500次写请求是可以允许异步化等待个几十秒，甚至几分钟后才落入数据库内的。

那么此时你完全可以引入消息中间件集群，把允许异步化的每秒500次请求写入MQ，然后基于MQ做一个削峰填谷。比如就以平稳的100/s的速度消费出来然后落入数据库中即可，此时就会大幅度降低数据库的写入压力。

### 消息队列

好处

1. 解耦, 不受对方影响, 通过队列联系
1. 提速, 只需加入队列即可
1. 很容易加入一个新客户端
1. 削峰, 高频压力慢慢收

成本

1. 引入空间复杂度
2. 暂时不一致性

非顺序消费时，消费失败后，`RocketMQ` 会如何处理？是直接丢弃该消息吗？还是一直重试直到消息消费成功？还是重试到一定次数就不再重试？`RocketMQ` 默认行为是：重试 16 次，16 次后还是失败，写入消费失败队列。



### 如何排查线上问题

**CPU 利用率高/飙升**

  监控系统突然告警，提示服务器负载异常。

- 频繁 gc
- 死循环、线程阻塞、io wait...etc

```shell
top` 定位CPU 最高的进程 `top \-Hp pid` 定位使用 CPU 最高的线程
`printf '0x%x' tid` 线程 id 转化 16 进制 
jstack pid | grep tid 找到线程堆栈
或者用一些脚本show-busy-java-threads , arthas
```

**线程池异常**  

RPC线程池满了, 对接口限流. 